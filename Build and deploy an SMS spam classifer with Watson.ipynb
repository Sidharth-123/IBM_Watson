{
    "cells": [
        {
            "metadata": {
                "collapsed": true
            },
            "cell_type": "markdown",
            "source": "# Build and deploy an SMS spam classifier with Watson Machine Learning\n**An Introduction to the Watson Machine Learning Python Client** <br> <br>\nThis notebook will show you how to build and deploy an SMS Spam Classifer with Watson Machine Learning and IBM Watson Studio. <br> We will use the new <a href=\"http://wml-api-pyclient.mybluemix.net/\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Machine Learning API Client for Python</a> which is available on `PyPi`. \n______\nThis notebook was tested in a `Python 3.6` Environment. \nThis notebook can be used as a companion to another <a href=\"https://medium.com/@adammassachi/dsx-hybrid-mode-91b580450c5b\" target=\"_blank\" rel=\"noopener noreferrer\">tutorial on our blog</a>.  <br>\n\n\n## Table of Contents\n1. [Load data](#load)\n2. [Build model](#build)\n3. [Save and deploy](#save)\n4. [Make API requests](#api)\n\n_____\n\n## 1. Load data <a id=\"load\"></a>\nFirst, install the Watson Machine Learning library via `pip` if you have not yet installed it. <br> We will use this library to communicate with Watson Machine Learning. The `python client` allows anyone with a Watson Machine Learning instance to programmatically save, load, and deploy models, among other tasks. "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip install watson-machine-learning-client --upgrade\n",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Requirement already up-to-date: watson-machine-learning-client in /opt/conda/envs/Python36/lib/python3.6/site-packages (1.0.378)\nRequirement already satisfied, skipping upgrade: certifi in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client) (2020.6.20)\nRequirement already satisfied, skipping upgrade: urllib3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client) (1.24.1)\nRequirement already satisfied, skipping upgrade: tqdm in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client) (4.31.1)\nRequirement already satisfied, skipping upgrade: lomond in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client) (0.3.3)\nRequirement already satisfied, skipping upgrade: ibm-cos-sdk in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client) (2.4.3)\nRequirement already satisfied, skipping upgrade: pandas in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client) (0.24.1)\nRequirement already satisfied, skipping upgrade: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client) (2.21.0)\nRequirement already satisfied, skipping upgrade: tabulate in /opt/conda/envs/Python36/lib/python3.6/site-packages (from watson-machine-learning-client) (0.8.2)\nRequirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from lomond->watson-machine-learning-client) (1.12.0)\nRequirement already satisfied, skipping upgrade: ibm-cos-sdk-core==2.*,>=2.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.4.3)\nRequirement already satisfied, skipping upgrade: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.4.3)\nRequirement already satisfied, skipping upgrade: numpy>=1.12.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas->watson-machine-learning-client) (1.15.4)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas->watson-machine-learning-client) (2.7.5)\nRequirement already satisfied, skipping upgrade: pytz>=2011k in /opt/conda/envs/Python36/lib/python3.6/site-packages (from pandas->watson-machine-learning-client) (2018.9)\nRequirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->watson-machine-learning-client) (2.8)\nRequirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->watson-machine-learning-client) (3.0.4)\nRequirement already satisfied, skipping upgrade: docutils>=0.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client) (0.14)\nRequirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client) (0.9.3)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The data we are looking to classify are SMS Messages which have been labeled `spam` or `ham`. You can find the data in the community. You can either download the data set to your environment and add it to your project, or you can read the data directly into a data frame as shown below. For more details on loading and accessing data, see <a href=\"https://datascience.ibm.com/docs/content/analyze-data/load-and-access-data.html\" target=\"_blank\" rel=\"noopener noreferrer\">Load and access data in a notebook</a>."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<!--comment: Simon, here you need to tell them how to access data. They can either (1) go to the community and download the csv with the 'add data' link above, \nor (2) import the csv directly as in the cell below. Either way, we should be explicit...  I'm trying to find a good example, and frankly, we don't have a really good one.\nHaving said that, you can have a look at https://github.com/IBMDataScience/sample-notebooks/blob/ec37c3f56f33cf8aa85c00e9081f13012ffd8fd5/Cloud/IPYNB/Watson%2Bconversation%2Bservice.ipynb\n-->"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import pandas as pd\ndf = pd.read_csv(\"https://dataplatform.ibm.com/exchange-api/v1/entries/e39fb7848165baca7fc0395025ba4e48/data?accessKey=36100ef896c27e41fdfc4a3029071d50\")",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Our first step will be converting the string label into a numeric representation. <br> \nWe can use a `pandas.Series method`,  `factorize()[0]`, to convert strings into numeric factors."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df = df[df.columns[:2]]\ndf.columns = ['ham', 'text']\ndf['label'] = df.ham.factorize()[0]\ndf['text'] = df.text.apply(lambda x: x.lower())",
            "execution_count": 3,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df.head()",
            "execution_count": 4,
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ham</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>go until jurong point, crazy.. available only ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>ok lar... joking wif u oni...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>u dun say so early hor... u c already then say...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>nah i don't think he goes to usf, he lives aro...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "    ham                                               text  label\n0   ham  go until jurong point, crazy.. available only ...      0\n1   ham                      ok lar... joking wif u oni...      0\n2  spam  free entry in 2 a wkly comp to win fa cup fina...      1\n3   ham  u dun say so early hor... u c already then say...      0\n4   ham  nah i don't think he goes to usf, he lives aro...      0"
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"build\"></a>\n## 2. Build a model \nWe will use `scikit-learn` to create a `Naive Bayes` model. <br>We will use the `HashingVectorizer`, which converts the SMS\u2019 text into a matrix representation suitable for modeling."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.feature_extraction.text import HashingVectorizer\nvectorizer = HashingVectorizer(n_features=5000, stop_words='english', non_negative=True)",
            "execution_count": 5,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We need to connect the output of the `vectorizer` to the input of the model. We will use `Multinomial Naive Bayes`, a Naive Bayes classifier which works well with the representation of our features\u200a \u2014\u200a integer representations of the word frequencies.\n\n\nNext, we will use `train_test_split` in order to divide the data into `testing` and `training` sets so that we can evaluate the performance of the model."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(df['text'], df['label'], random_state=0)",
            "execution_count": 6,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Next, we need to transform the text and fit the model."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# first transform the text data\ntransformed_x = vectorizer.fit_transform(x_train)\n\n# import the modules and fit\nfrom sklearn.naive_bayes import MultinomialNB\nbn = MultinomialNB().fit(transformed_x, y_train)",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We\u2019ve got a fit model in `bn`. Let\u2019s evaluate the performance on the test data after creating the pipeline."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# make a pipe\nfrom sklearn.pipeline import make_pipeline\npipe = make_pipeline(vectorizer, bn)",
            "execution_count": 8,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The pipe will sequentially transform the data according to the transformers specified, terminating in what scikit-learn calls an estimator. <br>Then, we can call predict or score, and so on."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pipe.predict_proba([\"URGENT! You have built a model - scroll down to see more\"])",
            "execution_count": 9,
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n  \" in version 0.21.\", DeprecationWarning)\n"
                },
                {
                    "data": {
                        "text/plain": "array([[0.79965197, 0.20034803]])"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's score."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pipe.score(x_test, y_test)",
            "execution_count": 10,
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n  \" in version 0.21.\", DeprecationWarning)\n"
                },
                {
                    "data": {
                        "text/plain": "0.9619799139167863"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "`96% accuracy`, not bad. You can experiment with different numbers of features and vectorizers for your model. You can also create other features that are not captured by the vectorizer, such as the length of the message. "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"save\"></a>\n## 3. Save and deploy\nAfter creating a model, you might want to make use of its predictions later. In order to do this, we will persist models with Watson Machine Learning. With WML, you can easily `save` and `deploy` models, among other powerful features. `Saving` a model makes this model portable -- as long as you can connect to WML, you can load your saved models into your environment. `Deploying` a model exposes the predictive capacity of the model as an API endpoint, which you can consume in applications, for example. \n\nUse the client to save your model to the WML Repository. From there, you can load and deploy models as well. If you don't already have a WML account, you can get more details <a href=\"https://dataplatform.ibm.com/docs/content/analyze-data/ml-setup.html\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>.\n\nFirst, we will import the library and specify our credentials. If you don't know where to find your credentials, they are available to you both in the Watson Studio Project and in IBM Cloud. "
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n\nwml_credentials = {\n    \"apikey\": \"\",\n    \"username\": \"\",\n    \"password\": \"\",\n    \"instance_id\": \"\",\n    \"url\": \"\"\n}",
            "execution_count": 11,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "client = WatsonMachineLearningAPIClient(wml_credentials)",
            "execution_count": 13,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We have connected to our WML Repository using the python package and our credentials. Publishing the model will save the model to our repository. "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "metadata = {\n            client.repository.ModelMetaNames.NAME: 'SPAM_MODEL',\n            client.repository.ModelMetaNames.FRAMEWORK_NAME: 'scikit-learn',\n            client.repository.ModelMetaNames.RUNTIME_NAME: 'python',\n            client.repository.ModelMetaNames.RUNTIME_VERSION: '3.6'\n}",
            "execution_count": 14,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# publish model \npublished_model_details = client.repository.store_model(model=pipe, meta_props=metadata, training_data=pd.DataFrame(df['text']), training_target=df['label'])",
            "execution_count": 15,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now that we have saved the model to the repository, we can load it into a python object using it's `uid`. First, let's look at the code."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# get my model ide\nguid = client.repository.get_model_uid(published_model_details)\nguid",
            "execution_count": 16,
            "outputs": [
                {
                    "data": {
                        "text/plain": "'4bd39f73-bfff-4660-8e5a-141f18c8c196'"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Load the model using its id and the `repository.load()` function. "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "mod = client.repository.load(guid)\ntype(mod)",
            "execution_count": 17,
            "outputs": [
                {
                    "data": {
                        "text/plain": "sklearn.pipeline.Pipeline"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Notice the type is an `sklearn` model, just as we created. "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# verify that the loaded model returns the same predictions as the model we developed in our environment. \nmod.predict_proba([\"URGENT! You have built a model - scroll down to see more\"])",
            "execution_count": 18,
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n  \" in version 0.21.\", DeprecationWarning)\n"
                },
                {
                    "data": {
                        "text/plain": "array([[0.79965197, 0.20034803]])"
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<a id=\"api\"></a>\n## 4. Test the API\nNow that we have successfully saved and loaded the model, we can create an API endpoint and make requests. "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "scoring_endpoint = client.deployments.create(name=\"SPAM-NEW\", model_uid=guid)",
            "execution_count": 19,
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '4bd39f73-bfff-4660-8e5a-141f18c8c196' started\n\n#######################################################################################\n\n\nINITIALIZING\nDEPLOY_SUCCESS\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='bf6c81d1-10e4-4917-b3fb-39cdddbdeb84'\n------------------------------------------------------------------------------------------------\n\n\n"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "scoring_endpoint_url = scoring_endpoint['entity']['scoring_url']",
            "execution_count": 20,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's create some JSON to send. We will use `client.deployments.score(scoring_url, payload)`. <a href=\"http://wml-api-pyclient.mybluemix.net/\" target=\"_blank\" rel=\"noopener noreferrer\">Read our docs</a> for more details. "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# create a payload\nmy_sms = \"Send me to the API por favor\"\n# list of lists\npayload = {\"fields\": [\"text\"], \"values\": [[my_sms]]}\n\n# make a request\nresponse = client.deployments.score(scoring_url=scoring_endpoint_url, payload=payload)",
            "execution_count": 21,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Let's check out the response."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "response",
            "execution_count": 22,
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'fields': ['prediction', 'probability'],\n 'values': [[0, [0.8211305335459812, 0.17886946645401927]]]}"
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "\n\n____________\n\n### Author\nAdam Massachi is a Data Scientist with the Watson Studio team at IBM. Before IBM, he worked on political campaigns, building and managing large volunteer operations and organizing campaign finance initiatives. Say hello <a href=\"https://twitter.com/adammassach?lang=en\" target=\"_blank\" rel=\"noopener noreferrer\">@adammassach</a>!\n\nCopyright \u00a9 IBM Corp. 2018, 2019. This notebook and its source code are released under the terms of the MIT License."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n</div>"
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}